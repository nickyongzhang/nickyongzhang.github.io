# jemdoc: menu{MENU}{projects.html}
= Yong Zhang -- Selected Projects

== Multiview Convolutional Neural Networks for Multidocument Extractive Summarization

~~~
Multidocument summarization has gained popularity in many real world applications because vital information can be extracted within a short time. Extractive summarization aims to generate a summary of a document or a set of documents by ranking sentences and the ranking results rely heavily on the quality of sentence features. However, almost all previous algorithms require hand-crafted features for sentence representation. In this paper, we leverage on word embedding to represent sentences so as to avoid the intensive labor in feature engineering. An enhanced convolutional neural networks (CNNs) termed multiview CNNs is successfully developed to obtain the features of sentences and rank sentences jointly. Multiview learning is incorporated into the model to greatly enhance the learning capability of original CNN. We evaluate the generic summarization performance of our proposed method on five Document Understanding Conference datasets. The proposed system outperforms the state-of-the-art approaches and the improvement is statistically significant shown by paired t-test.

*Related Papers*:
-  *Yong ZHANG*, Meng Joo ER, Rui ZHAO and Mahardhika PRATAMA, "/Multi-view Convolutional Neural Networks for Multi-document Extractive Summarization/", Cybernetics, IEEE Transactions on, 99(2016): 1-13, doi: 10.1109/TCYB.2016.2628402.\n
~~~

== Attention pooling-based convolutional neural network for sentence modelling

~~~
Convolutional neural network has been proven to be a powerful semantic composition model for modelling sentences. A standard convolutional neural network usually consists of several convolutional and pooling layers at the bottom of a linear or non-linear classi- fier. In this paper, a new pooling scheme termed Attention Pooling is proposed to retain the most significant information at the pooling stage. An intermediate sentence representation generated by the bidirectional long short-term memory is used as a reference for local representations produced by the convolutional layer to obtain attention weights. The sen- tence representation is formed by combining local representations using obtained atten- tion weights. The intermediate sentence representation is used as an input to the top clas- sifier as well in the testing phase. The salient features of the proposed attention pooling- based convolutional neural network are: (1) The model can be trained end-to-end with limited hyper-parameters; (2) Comprehensive information is extracted by the new pooling scheme and the combination of the convolutional layer and the bidirectional long-short term memory; (3) The model can implicitly separate the sentences from different classes. Experimental results demonstrate that the new model outperforms the state-of-the-art ap- proaches on seven benchmark datasets for text classification. The learning capability of the proposed method is greatly improved and the classification accuracy is even enhanced sig- nificantly by over 2% on some datasets. The robustness of the proposed model is evidenced by some statistical tests.

*Related Papers*:
- Meng Joo ER, *Yong ZHANG*, Ning WANG and Mahardhika PRATAMA. "/Attention Pooling-based Convolutional Neural Network for Sentence Modelling/", Information Science, 373(2016): 388-403. (corresponding author)\n
~~~

~~~
Please feel free to [yzhang067@e.ntu.edu.sg contact me].
~~~